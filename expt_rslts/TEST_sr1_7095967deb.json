{"specs": {"opt": "sr1", "dataset": "cifar10", "batch_size_train": 50000, "batch_size_test": 10000, "momentum": 0.0, "hidden": 15, "max_newton": 1, "abs_newton_tol": 1e-05, "rel_newton_tol": 1e-05, "max_cr": 50, "cr_tol": 0.001, "learning_rate": 1.0, "sufficient_decrease": 0.01, "curvature_condition": null, "extrapolation_factor": 0.9, "max_searches": 5, "num_epoch": 20, "seed": 100, "read_nn": null, "write_nn": true, "log_interval": 10, "device": "cuda", "record": "./expt_rslts/", "memory": 10}, "time": [9.893073229119182, 7.619679419323802, 6.943920325487852, 10.047101877629757, 7.155933905392885, 7.512251015752554, 10.106727724894881, 7.46672392077744, 10.39417133294046, 7.715209800750017, 7.505025343969464, 10.494823798537254, 10.14444368891418, 8.707255538553, 8.256373602896929, 9.919861385598779, 10.127892103046179, 9.921329483389854, 8.59923973120749, 9.696409780532122], "train_loss_list": [13.137040138244629, 11.61458969116211, 8.746381759643555, 10.973987579345703, 10.341117858886719, 10.316328048706055, 10.349101066589355, 10.320157051086426, 10.336821556091309, 10.336380004882812, 10.334806442260742, 10.33542537689209, 10.335494041442871, 10.335492134094238, 10.33548641204834, 10.335586547851562, 10.335580825805664, 10.335612297058105, 10.335616111755371, 10.335773468017578], "test_loss_list": [0.0005244380950927734, 0.0014614480018615723, 0.0008666203498840332, 0.0008569252967834472, 0.000930901050567627, 0.000936796760559082, 0.000989989185333252, 0.0010059900283813476, 0.0010248637199401856, 0.0010294679641723633, 0.001031868362426758, 0.00103537540435791, 0.0010362581253051757, 0.0010378982543945313, 0.001038382339477539, 0.0010376045227050781, 0.0010375397682189941, 0.0010372319221496583, 0.0010377293586730956, 0.0010379831314086914], "test_accuracy_list": [11.24, 14.09, 16.89, 18.16, 15.65, 15.82, 16.24, 16.29, 16.36, 16.3, 16.36, 16.4, 16.43, 16.43, 16.41, 16.41, 16.42, 16.41, 16.43, 16.43], "train_accuracy_list": [11.626, 15.52, 16.854, 17.786, 16.016, 16.052, 16.436, 16.374, 16.338, 16.382, 16.372, 16.374, 16.398, 16.396, 16.376, 16.39, 16.346, 16.374, 16.436, 16.446]}