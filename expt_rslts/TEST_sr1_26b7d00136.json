{"specs": {"opt": "sr1", "dataset": "cifar10", "batch_size_train": 50000, "batch_size_test": 10000, "momentum": 0.0, "hidden": 15, "max_newton": 1, "abs_newton_tol": 1e-06, "rel_newton_tol": 1e-06, "max_cr": 1, "cr_tol": 0.001, "learning_rate": 0.9, "sufficient_decrease": 0.001, "curvature_condition": null, "extrapolation_factor": 0.1, "max_searches": 5, "num_epoch": 20, "seed": 100, "read_nn": null, "write_nn": true, "log_interval": 10, "device": "cuda", "record": "./expt_rslts/", "memory": 1}, "time": [6.45076940767467, 8.094950437545776, 8.079883016645908, 8.098167831078172, 8.084217477589846, 8.105868674814701, 8.087683307006955, 8.12328216060996, 8.083497630432248, 8.084198856726289, 8.136863753199577, 8.102638842538, 8.15059745311737, 8.11889765970409, 8.083306165412068, 8.096438072621822, 8.115109046921134, 8.08590603992343, 8.106682039797306, 8.076578862965107], "train_loss_list": [2.413780927658081, 2.41398286819458, 2.4160759449005127, 2.4181418418884277, 2.4201786518096924, 2.4222891330718994, 2.4243788719177246, 2.4264843463897705, 2.428598642349243, 2.4307005405426025, 2.4328596591949463, 2.434997081756592, 2.437129497528076, 2.4392995834350586, 2.441490411758423, 2.4436910152435303, 2.4459407329559326, 2.44817852973938, 2.450428009033203, 2.4526658058166504], "test_loss_list": [0.00022832579612731935, 0.0002281965970993042, 0.00022945966720581054, 0.00023162479400634767, 0.0002331843376159668, 0.00023446969985961913, 0.0002359485149383545, 0.00023625881671905517, 0.0002357853412628174, 0.00023633272647857666, 0.0002373215675354004, 0.00023598172664642333, 0.00023620197772979736, 0.00023693442344665527, 0.00023761367797851563, 0.0002381227731704712, 0.00023747315406799315, 0.00023731694221496583, 0.0002377026081085205, 0.00023776774406433107], "test_accuracy_list": [14.33, 14.09, 15.05, 15.76, 16.23, 16.05, 15.83, 16.2, 16.05, 16.19, 15.86, 16.32, 15.88, 15.91, 15.8, 15.39, 15.63, 15.89, 15.31, 15.74], "train_accuracy_list": [16.838, 16.828, 16.8, 16.778, 16.746, 16.734, 16.72, 16.704, 16.67, 16.652, 16.63, 16.602, 16.582, 16.566, 16.54, 16.506, 16.484, 16.444, 16.432, 16.402]}