{"specs": {"opt": "sr1", "dataset": "cifar10", "batch_size_train": 50000, "batch_size_test": 10000, "momentum": 0.0, "hidden": 15, "max_newton": 1, "abs_newton_tol": 0.0001, "rel_newton_tol": 1e-07, "max_cr": 10, "cr_tol": 0.01, "learning_rate": 1.0, "sufficient_decrease": 0.01, "curvature_condition": null, "extrapolation_factor": 0.9, "max_searches": 10, "num_epoch": 20, "seed": 10, "read_nn": null, "write_nn": true, "log_interval": 10, "device": "cuda", "record": "./expt_rslts/", "memory": 2}, "time": [10.835645668208599, 10.259048644453287, 5.94906940869987, 5.930979797616601, 10.830982185900211, 10.837249260395765, 5.953147703781724, 5.908556874841452, 10.842346580699086, 5.91943483799696, 5.93537225574255, 10.79195299744606, 5.929115451872349, 6.01517459563911, 10.828698365017772, 6.0007029715925455, 5.923922011628747, 10.834966143593192, 5.920252090319991, 5.941621948033571], "train_loss_list": [6.843977451324463, 6.842535495758057, 6.645396709442139, 4.814626693725586, 5.249348163604736, 5.536312103271484, 4.175653457641602, 3.97288179397583, 4.182214260101318, 4.137783050537109, 4.074990749359131, 4.270488262176514, 4.138335704803467, 4.113133907318115, 4.1904191970825195, 4.139044761657715, 4.127296447753906, 4.145241737365723, 4.140103816986084, 4.129238605499268], "test_loss_list": [0.00035694282054901124, 0.0005199481010437012, 0.00226995906829834, 0.0007394533634185791, 0.0005570011138916016, 0.0005581247806549073, 0.000543096113204956, 0.0004376376628875732, 0.00042064833641052246, 0.0004318053722381592, 0.0004190850257873535, 0.0004293362617492676, 0.0004213274955749512, 0.0004168890476226807, 0.00042136602401733397, 0.0004213755130767822, 0.00041869215965270997, 0.00041841416358947756, 0.00042201123237609864, 0.0004194694995880127], "test_accuracy_list": [10.13, 16.27, 10.22, 17.09, 17.22, 14.67, 14.18, 14.77, 15.25, 15.34, 15.29, 15.22, 15.27, 15.23, 15.17, 15.33, 15.29, 14.95, 15.31, 15.22], "train_accuracy_list": [15.284, 17.34, 11.032, 16.372, 16.96, 14.662, 15.55, 15.804, 15.664, 15.804, 15.872, 15.516, 15.81, 15.846, 15.494, 15.81, 15.778, 15.484, 15.764, 15.712]}