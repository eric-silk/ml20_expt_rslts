{"specs": {"opt": "sr1", "dataset": "cifar10", "batch_size_train": 50000, "batch_size_test": 10000, "momentum": 0.0, "hidden": 15, "max_newton": 1, "abs_newton_tol": 1e-05, "rel_newton_tol": 1e-05, "max_cr": 50, "cr_tol": 0.001, "learning_rate": 1.0, "sufficient_decrease": 0.01, "curvature_condition": null, "extrapolation_factor": 0.9, "max_searches": 5, "num_epoch": 20, "seed": 10, "read_nn": null, "write_nn": true, "log_interval": 10, "device": "cuda", "record": "./expt_rslts/", "memory": 25}, "time": [9.0728311650455, 6.57945847325027, 6.592434337362647, 9.109562944620848, 6.639418685808778, 9.25519978441298, 9.14604895748198, 6.524133255705237, 8.960670955479145, 6.884390542283654, 6.980508668348193, 9.938505195081234, 7.00998068228364, 10.251165015622973, 7.755126720294356, 10.267723040655255, 8.367327708750963, 11.035647716373205, 11.336472447961569, 11.186837408691645], "train_loss_list": [11.499465942382812, 10.888842582702637, 7.979786396026611, 9.785529136657715, 9.059907913208008, 9.175283432006836, 9.379046440124512, 9.032011032104492, 9.252280235290527, 9.21640396118164, 9.211713790893555, 9.215060234069824, 9.213605880737305, 9.21462345123291, 9.214428901672363, 9.214509963989258, 9.214391708374023, 9.214444160461426, 9.214445114135742, 9.214519500732422], "test_loss_list": [0.00043382439613342286, 0.0011605280876159669, 0.0008906861305236816, 0.0009331761360168457, 0.0010152215957641602, 0.000912580394744873, 0.0009219788551330567, 0.0008818755149841308, 0.000893718433380127, 0.0008982372283935547, 0.0009018391609191894, 0.000909503173828125, 0.0009130987167358398, 0.0009176587104797364, 0.0009197546958923339, 0.0009199466705322266, 0.000919019889831543, 0.0009200069427490234, 0.000920690631866455, 0.0009205233573913574], "test_accuracy_list": [12.54, 13.74, 17.09, 11.4, 17.71, 17.85, 17.21, 17.3, 16.82, 17.12, 17.04, 16.98, 16.93, 16.91, 16.83, 16.84, 16.86, 16.86, 16.87, 16.84], "train_accuracy_list": [14.382, 15.49, 16.344, 11.454, 17.494, 17.256, 17.04, 16.972, 16.742, 16.902, 16.904, 16.882, 16.894, 16.916, 16.93, 16.912, 16.894, 16.86, 16.88, 16.91]}