{"specs": {"opt": "sr1", "dataset": "cifar10", "batch_size_train": 50000, "batch_size_test": 10000, "momentum": 0.0, "hidden": 15, "max_newton": 1, "abs_newton_tol": 1e-06, "rel_newton_tol": 1e-05, "max_cr": 1, "cr_tol": 0.001, "learning_rate": 2.0, "sufficient_decrease": 0.01, "curvature_condition": null, "extrapolation_factor": 0.1, "max_searches": 5, "num_epoch": 20, "seed": 1, "read_nn": null, "write_nn": true, "log_interval": 10, "device": "cuda", "record": "./expt_rslts/", "memory": 2}, "time": [7.064437672495842, 8.189714349806309, 8.146697456017137, 8.161216763779521, 8.152220821008086, 8.15353581495583, 8.148690653964877, 8.191020712256432, 8.137822741642594, 8.14521668665111, 8.131422605365515, 8.164002569392323, 8.244257863610983, 8.162780137732625, 8.220504336059093, 8.16927745938301, 8.164635410532355, 8.161447228863835, 8.187126640230417, 8.141531588509679], "train_loss_list": [2.360584020614624, 2.3615055084228516, 2.362470865249634, 2.363435983657837, 2.3644003868103027, 2.36535906791687, 2.3663134574890137, 2.367265462875366, 2.3682146072387695, 2.3691625595092773, 2.370107889175415, 2.371058225631714, 2.3720102310180664, 2.372957706451416, 2.3738961219787598, 2.37483811378479, 2.375781774520874, 2.376725912094116, 2.377673387527466, 2.378618001937866], "test_loss_list": [0.00023208515644073486, 0.00023239524364471436, 0.0002365910768508911, 0.00024188625812530517, 0.00024565322399139404, 0.0002480934143066406, 0.0002491243600845337, 0.00024988288879394533, 0.0002498656272888184, 0.0002499849557876587, 0.00024974572658538816, 0.00024972965717315673, 0.0002499517917633057, 0.00025053312778472903, 0.00025053303241729736, 0.00025091352462768555, 0.0002510575294494629, 0.00025112400054931643, 0.00025080852508544923, 0.0002513114929199219], "test_accuracy_list": [10.21, 10.06, 10.09, 10.14, 10.15, 9.99, 9.96, 9.98, 10.19, 10.22, 10.21, 10.1, 10.1, 10.0, 10.35, 10.38, 10.27, 10.06, 9.8, 10.42], "train_accuracy_list": [13.144, 13.132, 13.098, 13.028, 12.992, 12.948, 12.904, 12.888, 12.868, 12.842, 12.828, 12.802, 12.782, 12.774, 12.758, 12.724, 12.684, 12.638, 12.622, 12.59]}